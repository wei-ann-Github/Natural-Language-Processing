{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\n\nimport pandas as pd\n# import pytorch_lightning as pl\nimport spacy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchtext\nfrom tqdm.notebook import tqdm\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"pytorch version: {torch.__version__}\")\nprint(f\"torchtext version: {torchtext.__version__}\")","execution_count":47,"outputs":[{"output_type":"stream","text":"pytorch version: 1.4.0\ntorchtext version: 0.5.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# look at the data\ntrain_filename = '/kaggle/input/nlp-getting-started/train.csv'\ntr_df = pd.read_csv(train_filename, engine='python')\ndisplay(tr_df.head())\nprint(tr_df.shape)\nprint(tr_df.target.value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Torchtext"},{"metadata":{"trusted":true},"cell_type":"code","source":"class spacy_tokenizer:\n    def __init__(self, lang):\n        self.lang = lang\n        self.nlp = spacy.blank(self.lang)\n        \n    def __call__(self, text):\n        return [token.text for token in self.nlp(text)]\n\ntokenizer = spacy_tokenizer('en')\nTEXT = torchtext.data.Field(tokenize=tokenizer, lower=True)\nLABEL = torchtext.data.LabelField(use_vocab=False)\n\nfields = [('id', None), ('keyword', None), ('location', None), ('text', TEXT), ('target', LABEL)]\ndataset = torchtext.data.TabularDataset(path=train_filename, format='csv', fields=fields, skip_header=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split into train and validation dataset.\ntr_data, val_data = dataset.split(split_ratio=0.8)\nprint(len(tr_data), len(val_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build vocab\nTEXT.build_vocab(tr_data)\nprint('num vocab', len(TEXT.vocab))\n\nmax_size = 20000\nTEXT.build_vocab(tr_data, max_size=max_size)\nprint('num vocab', len(TEXT.vocab))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iterator\nbatch_size = 32\ntr_iter = torchtext.data.BucketIterator(tr_data, batch_size=batch_size, shuffle=True, device=device)\nval_iter = torchtext.data.BucketIterator(val_data, batch_size=batch_size, shuffle=False, device=device)  # do not use train=False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The network"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Rnn(nn.Module):\n    def __init__(self, input_size, embedding_dim, hidden_dim, output_size, bidirectional=False, n_layers=1, dropout=0, rnn_type='rnn'):\n        super().__init__()\n        self.bidirectional = bidirectional\n        self.n_layers = n_layers\n        self.rnn_type = rnn_type\n        self.dropout = dropout\n        \n        self.embedding = nn.Embedding(input_size, embedding_dim)\n        self.encoder = getattr(nn, rnn_type.upper())(embedding_dim, hidden_dim, bidirectional=bidirectional, num_layers=n_layers, dropout=dropout)\n        \n        in_features = hidden_dim\n        if self.bidirectional:\n            in_features *= 2\n            \n        self.fc = nn.Linear(in_features=in_features, out_features=output_size)\n        \n    def forward(self, x):\n        x = self.embedding(x)\n        if self.rnn_type.upper() == 'LSTM':\n            x, (h_, c_) = self.encoder(x)\n        else:\n            x, h_ = self.encoder(x)\n\n        x = self.fc(x[-1])\n        \n        return x","execution_count":28,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{},"cell_type":"markdown","source":"## RNN v.s. LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Single layer, unidirectional Vanilla RNN\ninput_size = len(TEXT.vocab)\nembedding_dim = 100\nhidden_dim = 100\noutput_size = 1\nbidirectional = False\nn_layers = 1\ndropout = 0\nrnn_type = 'rnn'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.686143, Validation loss 0.015258, Accuracy 56.5332 %\nEnd epoch 2: Train loss 0.684107, Validation loss 0.015248, Accuracy 56.5988 %\nEnd epoch 3: Train loss 0.683151, Validation loss 0.015320, Accuracy 56.5332 %\nEnd epoch 4: Train loss 0.682251, Validation loss 0.015335, Accuracy 56.3362 %\nEnd epoch 5: Train loss 0.682430, Validation loss 0.015022, Accuracy 56.3362 %\nEnd epoch 6: Train loss 0.681414, Validation loss 0.015875, Accuracy 56.3362 %\nEnd epoch 7: Train loss 0.680970, Validation loss 0.015566, Accuracy 56.3362 %\nEnd epoch 8: Train loss 0.681566, Validation loss 0.015377, Accuracy 56.4675 %\nEnd epoch 9: Train loss 0.680608, Validation loss 0.015740, Accuracy 56.5988 %\nEnd epoch 10: Train loss 0.680145, Validation loss 0.015657, Accuracy 56.4675 %\nEnd epoch 11: Train loss 0.679780, Validation loss 0.015750, Accuracy 56.3362 %\nEnd epoch 12: Train loss 0.679465, Validation loss 0.016013, Accuracy 56.2705 %\nEnd epoch 13: Train loss 0.679475, Validation loss 0.015992, Accuracy 56.3362 %\nEnd epoch 14: Train loss 0.678629, Validation loss 0.015282, Accuracy 56.4018 %\nEnd epoch 15: Train loss 0.677867, Validation loss 0.015790, Accuracy 56.2705 %\nEnd epoch 16: Train loss 0.675825, Validation loss 0.015406, Accuracy 56.2705 %\nEnd epoch 17: Train loss 0.654834, Validation loss 0.012689, Accuracy 63.6901 %\nEnd epoch 18: Train loss 0.632864, Validation loss 0.013261, Accuracy 64.4780 %\nEnd epoch 19: Train loss 0.631302, Validation loss 0.012478, Accuracy 66.2508 %\nEnd epoch 20: Train loss 0.616545, Validation loss 0.012476, Accuracy 62.9022 %\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Single layer, unidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 100\nhidden_dim = 100\noutput_size = 1\nbidirectional = False\nn_layers = 1\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":31,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f87c3b720fa474aae589ba44e216d29"}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.686149, Validation loss 0.015434, Accuracy 56.1392 %\nEnd epoch 2: Train loss 0.683519, Validation loss 0.015391, Accuracy 56.2049 %\nEnd epoch 3: Train loss 0.681743, Validation loss 0.015376, Accuracy 56.4018 %\nEnd epoch 4: Train loss 0.670921, Validation loss 0.015600, Accuracy 60.2101 %\nEnd epoch 5: Train loss 0.659021, Validation loss 0.014993, Accuracy 64.4123 %\nEnd epoch 6: Train loss 0.625467, Validation loss 0.013794, Accuracy 64.5437 %\nEnd epoch 7: Train loss 0.585155, Validation loss 0.013000, Accuracy 66.5135 %\nEnd epoch 8: Train loss 0.549042, Validation loss 0.012691, Accuracy 67.1701 %\nEnd epoch 9: Train loss 0.540150, Validation loss 0.011936, Accuracy 69.4682 %\nEnd epoch 10: Train loss 0.513276, Validation loss 0.011784, Accuracy 67.4327 %\nEnd epoch 11: Train loss 0.493698, Validation loss 0.012312, Accuracy 68.3519 %\nEnd epoch 12: Train loss 0.470956, Validation loss 0.012282, Accuracy 68.8116 %\nEnd epoch 13: Train loss 0.456053, Validation loss 0.011856, Accuracy 69.2055 %\nEnd epoch 14: Train loss 0.436003, Validation loss 0.013214, Accuracy 68.3519 %\nEnd epoch 15: Train loss 0.421967, Validation loss 0.011411, Accuracy 69.2712 %\nEnd epoch 16: Train loss 0.403168, Validation loss 0.012942, Accuracy 67.3670 %\nEnd epoch 17: Train loss 0.384846, Validation loss 0.012678, Accuracy 67.0387 %\nEnd epoch 18: Train loss 0.365616, Validation loss 0.014101, Accuracy 68.2206 %\nEnd epoch 19: Train loss 0.349185, Validation loss 0.013203, Accuracy 69.3368 %\nEnd epoch 20: Train loss 0.329972, Validation loss 0.014053, Accuracy 68.7459 %\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Number of layers"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Triple layer, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 100\nhidden_dim = 100\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).tcvvo(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":33,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.686180, Validation loss 0.015408, Accuracy 56.5988 %\nEnd epoch 2: Train loss 0.682783, Validation loss 0.014874, Accuracy 56.5988 %\nEnd epoch 3: Train loss 0.654599, Validation loss 0.013325, Accuracy 67.4984 %\nEnd epoch 4: Train loss 0.604910, Validation loss 0.012273, Accuracy 71.1097 %\nEnd epoch 5: Train loss 0.573841, Validation loss 0.012418, Accuracy 72.2915 %\nEnd epoch 6: Train loss 0.542105, Validation loss 0.013624, Accuracy 71.7663 %\nEnd epoch 7: Train loss 0.518034, Validation loss 0.012863, Accuracy 71.8976 %\nEnd epoch 8: Train loss 0.489685, Validation loss 0.013815, Accuracy 73.8674 %\nEnd epoch 9: Train loss 0.471655, Validation loss 0.013798, Accuracy 73.4077 %\nEnd epoch 10: Train loss 0.445759, Validation loss 0.014342, Accuracy 71.5693 %\nEnd epoch 11: Train loss 0.419717, Validation loss 0.014549, Accuracy 73.2764 %\nEnd epoch 12: Train loss 0.398545, Validation loss 0.015164, Accuracy 73.3421 %\nEnd epoch 13: Train loss 0.375532, Validation loss 0.016722, Accuracy 73.8017 %\nEnd epoch 14: Train loss 0.352309, Validation loss 0.015450, Accuracy 73.4077 %\nEnd epoch 15: Train loss 0.328246, Validation loss 0.016086, Accuracy 73.6047 %\nEnd epoch 16: Train loss 0.303377, Validation loss 0.018769, Accuracy 73.4734 %\nEnd epoch 17: Train loss 0.279408, Validation loss 0.016787, Accuracy 74.9179 %\nEnd epoch 18: Train loss 0.260562, Validation loss 0.017679, Accuracy 75.1806 %\nEnd epoch 19: Train loss 0.252437, Validation loss 0.015725, Accuracy 75.5745 %\nEnd epoch 20: Train loss 0.237921, Validation loss 0.020889, Accuracy 73.4734 %\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 5 layers, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 100\nhidden_dim = 100\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4969a82195346ed9c7cac742c00a02b"}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.684374, Validation loss 0.015940, Accuracy 56.5988 %\nEnd epoch 2: Train loss 0.682356, Validation loss 0.015918, Accuracy 56.5988 %\nEnd epoch 3: Train loss 0.665244, Validation loss 0.018898, Accuracy 57.3867 %\nEnd epoch 4: Train loss 0.620694, Validation loss 0.017384, Accuracy 66.1195 %\nEnd epoch 5: Train loss 0.576020, Validation loss 0.017279, Accuracy 67.3014 %\nEnd epoch 6: Train loss 0.556717, Validation loss 0.018272, Accuracy 67.5640 %\nEnd epoch 7: Train loss 0.533663, Validation loss 0.016539, Accuracy 69.6651 %\nEnd epoch 8: Train loss 0.514650, Validation loss 0.018890, Accuracy 68.4176 %\nEnd epoch 9: Train loss 0.494808, Validation loss 0.018009, Accuracy 69.2712 %\nEnd epoch 10: Train loss 0.480799, Validation loss 0.015229, Accuracy 72.7511 %\nEnd epoch 11: Train loss 0.465374, Validation loss 0.018371, Accuracy 70.9783 %\nEnd epoch 12: Train loss 0.451322, Validation loss 0.019400, Accuracy 69.2055 %\nEnd epoch 13: Train loss 0.431649, Validation loss 0.020061, Accuracy 70.9127 %\nEnd epoch 14: Train loss 0.412304, Validation loss 0.019417, Accuracy 71.1753 %\nEnd epoch 15: Train loss 0.383496, Validation loss 0.020256, Accuracy 70.9127 %\nEnd epoch 16: Train loss 0.367057, Validation loss 0.020574, Accuracy 70.2561 %\nEnd epoch 17: Train loss 0.343180, Validation loss 0.023802, Accuracy 69.7965 %\nEnd epoch 18: Train loss 0.329942, Validation loss 0.026317, Accuracy 68.2863 %\nEnd epoch 19: Train loss 0.311684, Validation loss 0.020046, Accuracy 71.4380 %\nEnd epoch 20: Train loss 0.290672, Validation loss 0.022059, Accuracy 70.1904 %\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 7 layers, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 100\nhidden_dim = 100\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2857fdc31bf048f3a05a56b69454a44f"}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.684439, Validation loss 0.015396, Accuracy 56.5988 %\nEnd epoch 2: Train loss 0.681865, Validation loss 0.014990, Accuracy 56.5988 %\nEnd epoch 3: Train loss 0.667820, Validation loss 0.014766, Accuracy 67.3670 %\nEnd epoch 4: Train loss 0.615748, Validation loss 0.011910, Accuracy 69.2712 %\nEnd epoch 5: Train loss 0.590287, Validation loss 0.011234, Accuracy 71.5036 %\nEnd epoch 6: Train loss 0.568022, Validation loss 0.012401, Accuracy 73.5391 %\nEnd epoch 7: Train loss 0.576193, Validation loss 0.015705, Accuracy 71.1097 %\nEnd epoch 8: Train loss 0.578437, Validation loss 0.014177, Accuracy 71.4380 %\nEnd epoch 9: Train loss 0.565581, Validation loss 0.012663, Accuracy 70.7157 %\nEnd epoch 10: Train loss 0.580068, Validation loss 0.013803, Accuracy 67.8267 %\nEnd epoch 11: Train loss 0.571825, Validation loss 0.014175, Accuracy 71.1753 %\nEnd epoch 12: Train loss 0.569560, Validation loss 0.012805, Accuracy 64.4780 %\nEnd epoch 13: Train loss 0.572228, Validation loss 0.011429, Accuracy 72.4228 %\nEnd epoch 14: Train loss 0.550255, Validation loss 0.012364, Accuracy 70.9127 %\nEnd epoch 15: Train loss 0.532890, Validation loss 0.012219, Accuracy 72.5542 %\nEnd epoch 16: Train loss 0.548610, Validation loss 0.012672, Accuracy 71.7663 %\nEnd epoch 17: Train loss 0.539014, Validation loss 0.013032, Accuracy 72.2915 %\nEnd epoch 18: Train loss 0.533344, Validation loss 0.013162, Accuracy 71.5036 %\nEnd epoch 19: Train loss 0.525581, Validation loss 0.012673, Accuracy 72.7511 %\nEnd epoch 20: Train loss 0.509033, Validation loss 0.013109, Accuracy 72.8825 %\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Embedding Dimensions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Triple layer, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 300\nhidden_dim = 100\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":43,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"397ce3c214394391bb5b0b1b93a15055"}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.685582, Validation loss 0.015646, Accuracy 56.5988 %\nEnd epoch 2: Train loss 0.680227, Validation loss 0.015636, Accuracy 56.7301 %\nEnd epoch 3: Train loss 0.650998, Validation loss 0.016594, Accuracy 61.1293 %\nEnd epoch 4: Train loss 0.565917, Validation loss 0.014101, Accuracy 68.4176 %\nEnd epoch 5: Train loss 0.481096, Validation loss 0.013798, Accuracy 71.6349 %\nEnd epoch 6: Train loss 0.419266, Validation loss 0.012927, Accuracy 74.9836 %\nEnd epoch 7: Train loss 0.362948, Validation loss 0.013514, Accuracy 73.6704 %\nEnd epoch 8: Train loss 0.311605, Validation loss 0.014887, Accuracy 75.7058 %\nEnd epoch 9: Train loss 0.272454, Validation loss 0.015892, Accuracy 75.6402 %\nEnd epoch 10: Train loss 0.249996, Validation loss 0.015541, Accuracy 75.1149 %\nEnd epoch 11: Train loss 0.226640, Validation loss 0.015989, Accuracy 74.8523 %\nEnd epoch 12: Train loss 0.220490, Validation loss 0.015892, Accuracy 74.3926 %\nEnd epoch 13: Train loss 0.202969, Validation loss 0.017959, Accuracy 75.9028 %\nEnd epoch 14: Train loss 0.191651, Validation loss 0.018040, Accuracy 75.4432 %\nEnd epoch 15: Train loss 0.185387, Validation loss 0.017699, Accuracy 75.2462 %\nEnd epoch 16: Train loss 0.197213, Validation loss 0.020140, Accuracy 75.1149 %\nEnd epoch 17: Train loss 0.176893, Validation loss 0.019339, Accuracy 75.3119 %\nEnd epoch 18: Train loss 0.162884, Validation loss 0.024436, Accuracy 74.9179 %\nEnd epoch 19: Train loss 0.150723, Validation loss 0.027399, Accuracy 73.4734 %\nEnd epoch 20: Train loss 0.142667, Validation loss 0.024990, Accuracy 74.5896 %\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Triple layer, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 500\nhidden_dim = 100\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.684637, Validation loss 0.015275, Accuracy 56.5988 %\nEnd epoch 2: Train loss 0.673158, Validation loss 0.015994, Accuracy 61.7859 %\nEnd epoch 3: Train loss 0.612146, Validation loss 0.016260, Accuracy 70.9127 %\nEnd epoch 4: Train loss 0.520551, Validation loss 0.013961, Accuracy 74.3270 %\nEnd epoch 5: Train loss 0.439461, Validation loss 0.013831, Accuracy 75.6402 %\nEnd epoch 6: Train loss 0.359533, Validation loss 0.013396, Accuracy 75.5745 %\nEnd epoch 7: Train loss 0.309813, Validation loss 0.015710, Accuracy 75.6402 %\nEnd epoch 8: Train loss 0.271392, Validation loss 0.016900, Accuracy 76.3624 %\nEnd epoch 9: Train loss 0.236591, Validation loss 0.014860, Accuracy 76.0998 %\nEnd epoch 10: Train loss 0.224945, Validation loss 0.021270, Accuracy 74.9836 %\nEnd epoch 11: Train loss 0.197351, Validation loss 0.018441, Accuracy 76.2968 %\nEnd epoch 12: Train loss 0.186057, Validation loss 0.018582, Accuracy 76.8221 %\nEnd epoch 13: Train loss 0.177162, Validation loss 0.021279, Accuracy 76.7564 %\nEnd epoch 14: Train loss 0.169450, Validation loss 0.021948, Accuracy 76.3624 %\nEnd epoch 15: Train loss 0.160481, Validation loss 0.021951, Accuracy 76.8221 %\nEnd epoch 16: Train loss 0.150998, Validation loss 0.023293, Accuracy 76.2311 %\nEnd epoch 17: Train loss 0.143322, Validation loss 0.020883, Accuracy 77.0190 %\nEnd epoch 18: Train loss 0.136615, Validation loss 0.021410, Accuracy 76.1655 %\nEnd epoch 19: Train loss 0.134461, Validation loss 0.019322, Accuracy 76.7564 %\nEnd epoch 20: Train loss 0.118727, Validation loss 0.019812, Accuracy 75.3119 %\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Hidden Dim"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Triple layer, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 500\nhidden_dim = 300\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":44,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7d16e4624ad44fa99dade962ae9aac9"}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.683744, Validation loss 0.015565, Accuracy 56.5988 %\nEnd epoch 2: Train loss 0.632728, Validation loss 0.014105, Accuracy 71.5693 %\nEnd epoch 3: Train loss 0.511221, Validation loss 0.011944, Accuracy 77.0190 %\nEnd epoch 4: Train loss 0.398272, Validation loss 0.010631, Accuracy 76.2968 %\nEnd epoch 5: Train loss 0.321018, Validation loss 0.014552, Accuracy 77.2160 %\nEnd epoch 6: Train loss 0.247653, Validation loss 0.012144, Accuracy 77.8726 %\nEnd epoch 7: Train loss 0.220850, Validation loss 0.015627, Accuracy 76.8877 %\nEnd epoch 8: Train loss 0.182591, Validation loss 0.015839, Accuracy 75.7715 %\nEnd epoch 9: Train loss 0.156471, Validation loss 0.017419, Accuracy 76.4938 %\nEnd epoch 10: Train loss 0.135555, Validation loss 0.013744, Accuracy 76.6907 %\nEnd epoch 11: Train loss 0.117362, Validation loss 0.011401, Accuracy 76.0998 %\nEnd epoch 12: Train loss 0.102122, Validation loss 0.017444, Accuracy 77.2160 %\nEnd epoch 13: Train loss 0.088683, Validation loss 0.016436, Accuracy 77.6100 %\nEnd epoch 14: Train loss 0.073901, Validation loss 0.018159, Accuracy 78.3979 %\nEnd epoch 15: Train loss 0.062269, Validation loss 0.018408, Accuracy 76.3624 %\nEnd epoch 16: Train loss 0.066031, Validation loss 0.017027, Accuracy 77.1504 %\nEnd epoch 17: Train loss 0.066027, Validation loss 0.014662, Accuracy 76.2311 %\nEnd epoch 18: Train loss 0.054244, Validation loss 0.018083, Accuracy 76.6907 %\nEnd epoch 19: Train loss 0.037383, Validation loss 0.022184, Accuracy 77.1504 %\nEnd epoch 20: Train loss 0.031784, Validation loss 0.022226, Accuracy 76.9534 %\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Triple layer, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 500\nhidden_dim = 500\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26334cb39334461a8e77b65da63b57fb"}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.684893, Validation loss 0.014801, Accuracy 56.5988 %\nEnd epoch 2: Train loss 0.666376, Validation loss 0.012886, Accuracy 69.4682 %\nEnd epoch 3: Train loss 0.537706, Validation loss 0.012002, Accuracy 75.0492 %\nEnd epoch 4: Train loss 0.417694, Validation loss 0.010023, Accuracy 76.0341 %\nEnd epoch 5: Train loss 0.328530, Validation loss 0.011392, Accuracy 75.9028 %\nEnd epoch 6: Train loss 0.262488, Validation loss 0.009441, Accuracy 76.9534 %\nEnd epoch 7: Train loss 0.199080, Validation loss 0.011625, Accuracy 76.7564 %\nEnd epoch 8: Train loss 0.158422, Validation loss 0.014837, Accuracy 74.3270 %\nEnd epoch 9: Train loss 0.113986, Validation loss 0.017211, Accuracy 75.4432 %\nEnd epoch 10: Train loss 0.096302, Validation loss 0.019391, Accuracy 76.2311 %\nEnd epoch 11: Train loss 0.067376, Validation loss 0.020576, Accuracy 74.9836 %\nEnd epoch 12: Train loss 0.065516, Validation loss 0.032031, Accuracy 72.2915 %\nEnd epoch 13: Train loss 0.055510, Validation loss 0.024696, Accuracy 72.8168 %\nEnd epoch 14: Train loss 0.038318, Validation loss 0.022754, Accuracy 73.9987 %\nEnd epoch 15: Train loss 0.044382, Validation loss 0.018128, Accuracy 74.9179 %\nEnd epoch 16: Train loss 0.027380, Validation loss 0.022130, Accuracy 74.3926 %\nEnd epoch 17: Train loss 0.028007, Validation loss 0.025997, Accuracy 74.9179 %\nEnd epoch 18: Train loss 0.031053, Validation loss 0.025886, Accuracy 74.2613 %\nEnd epoch 19: Train loss 0.035957, Validation loss 0.024350, Accuracy 73.0138 %\nEnd epoch 20: Train loss 0.025136, Validation loss 0.028935, Accuracy 75.4432 %\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Triple layer, biidirectional RNN with LSTM cell.\ninput_size = len(TEXT.vocab)\nembedding_dim = 500\nhidden_dim = 700\noutput_size = 1\nbidirectional = True\nn_layers = 3\ndropout = 0\nrnn_type = 'lstm'\nlr = 0.0001\nnum_epochs = 20\n\nmodel = Rnn(input_size, embedding_dim, hidden_dim, output_size, bidirectional=bidirectional, n_layers=n_layers, dropout=dropout, rnn_type=rnn_type).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.BCEWithLogitsLoss()\n\nfor epoch in tqdm(range(num_epochs)):\n    model.train()\n    tr_loss = 0\n    for idx, batch in enumerate(tr_iter):\n        optimizer.zero_grad()\n        \n        x, y = batch\n        \n        logits = model(x)\n        loss = criterion(logits.squeeze().to(float), y.to(float))\n        tr_loss += loss.item()\n        \n        loss.backward()\n        optimizer.step()\n        \n    tr_loss /= (idx + 1)\n    \n    with torch.no_grad():\n        model.eval()\n        num_correct = 0\n        val_loss = 0\n        for idx, batch in enumerate(val_iter):\n            x, y = batch\n            \n            logits = model(x)\n            loss = criterion(logits.squeeze().to(float), y.to(float))\n            val_loss = loss.item()\n            \n            \n            prediction = torch.sigmoid(logits)\n            prediction = (prediction >= 0.5).to(int).squeeze()\n            num_correct += sum(prediction == y)\n            \n        val_loss = loss / (idx + 1)\n        accuracy = num_correct.item() / len(val_data) * 100\n    \n    print(f'End epoch {epoch + 1}: Train loss {tr_loss:.6f}, Validation loss {val_loss:.6f}, Accuracy {accuracy:.4f} %')","execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ca672a447404bac9fa83eab4df0b1cc"}},"metadata":{}},{"output_type":"stream","text":"End epoch 1: Train loss 0.684151, Validation loss 0.014847, Accuracy 56.6645 %\nEnd epoch 2: Train loss 0.627720, Validation loss 0.017618, Accuracy 67.6953 %\nEnd epoch 3: Train loss 0.538095, Validation loss 0.015783, Accuracy 76.4281 %\nEnd epoch 4: Train loss 0.438291, Validation loss 0.016437, Accuracy 75.1149 %\nEnd epoch 5: Train loss 0.356982, Validation loss 0.012747, Accuracy 76.5594 %\nEnd epoch 6: Train loss 0.296356, Validation loss 0.015456, Accuracy 77.0847 %\nEnd epoch 7: Train loss 0.219451, Validation loss 0.022575, Accuracy 77.3473 %\nEnd epoch 8: Train loss 0.177110, Validation loss 0.015675, Accuracy 77.6756 %\nEnd epoch 9: Train loss 0.155142, Validation loss 0.016791, Accuracy 76.2968 %\nEnd epoch 10: Train loss 0.122729, Validation loss 0.015252, Accuracy 77.6756 %\nEnd epoch 11: Train loss 0.103109, Validation loss 0.018042, Accuracy 77.0190 %\nEnd epoch 12: Train loss 0.087596, Validation loss 0.026503, Accuracy 76.0998 %\nEnd epoch 13: Train loss 0.081479, Validation loss 0.022256, Accuracy 75.4432 %\nEnd epoch 14: Train loss 0.068149, Validation loss 0.015858, Accuracy 74.8523 %\nEnd epoch 15: Train loss 0.057828, Validation loss 0.017235, Accuracy 76.4938 %\nEnd epoch 16: Train loss 0.051451, Validation loss 0.025427, Accuracy 76.2311 %\nEnd epoch 17: Train loss 0.073960, Validation loss 0.023278, Accuracy 76.9534 %\nEnd epoch 18: Train loss 0.052080, Validation loss 0.026777, Accuracy 76.8221 %\nEnd epoch 19: Train loss 0.042429, Validation loss 0.023400, Accuracy 75.7715 %\nEnd epoch 20: Train loss 0.036970, Validation loss 0.021001, Accuracy 75.3119 %\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Summary of Performance"},{"metadata":{},"cell_type":"markdown","source":"|RNN Cell|num_layers|directionality|Embedding_dim|Hidden_dim|validation accuracy|\n|---|---|---|---|---|\n|RNN|1|unidirectional|100|100|66.25 %|\n|LSTM|1|unidirectional|100|100|69.34%|\n|LSTM|3|bidirectional|100|100|75.57%|\n|LSTM|5|bidirectional|100|100|72.75%|\n|LSTM|7|bidirectional|100|100|73.54%|\n|LSTM|3|bidirectional|300|100|75.71%|\n|LSTM|3|bidirectional|500|100|77.02%|\n|**LSTM\\***|**3**|**bidirectional**|**500**|**300**|**78.39%** (14 epochs)|\n|LSTM|3|bidirectional|500|500|76.23%|\n|LSTM|3|bidirectional|500|700|77.68%|"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}